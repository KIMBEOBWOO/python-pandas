{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 누락 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# info() 메소드\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info() 메소드를 통해 확인한 결과,  \n",
    "타이타닉 데이터셋의 총 891 개의 행 중, non-null (유효한 값)의 개수를 파악 할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    688\n",
      "C       59\n",
      "B       47\n",
      "D       33\n",
      "E       32\n",
      "A       15\n",
      "F       13\n",
      "G        4\n",
      "Name: deck, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# value_counts() 메소드\n",
    "print(df['deck'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_counts(dropna=False) 메소드를 통해 확인한 결과,  \n",
    "nan 값이 688개 존재하는것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n",
      "\n",
      "############################################################\n",
      "\n",
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n",
      "\n",
      "############################################################\n",
      "\n",
      "survived       5\n",
      "pclass         5\n",
      "sex            5\n",
      "age            5\n",
      "sibsp          5\n",
      "parch          5\n",
      "fare           5\n",
      "embarked       5\n",
      "class          5\n",
      "who            5\n",
      "adult_male     5\n",
      "deck           2\n",
      "embark_town    5\n",
      "alive          5\n",
      "alone          5\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# isnull() 메소드와 notnull() 메소드\n",
    "print(df.head().isnull())\n",
    "print('\\n############################################################\\n')\n",
    "print(df.head().notnull())\n",
    "\n",
    "# isnull() 메소드와 notnull() 메소드를 통한 누락 데이터 개수 확인\n",
    "print(df.head().isnull().sum(axis=0))\n",
    "print('\\n############################################################\\n')\n",
    "print(df.head().notnull().sum(axis=0)) # axis=0 일 경우 각 행의 합을, axis=1 일 경우 하나의 행의 열의 합을 구한다.\n",
    "\n",
    "# 반환값은 진위값으로 구성된 데이터프레임\n",
    "print(type(df.head().isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isnull() 메소드는 데이터프레임의 각 원소에 대해 원소값이 누락 데이터일 경우 True 를 반환하고  \n",
    "notnull() 메소드는 데이터프레임의 각 원소에 대해 원소값이 유효 데이터일 경우 True 를 반환한다.  \n",
    "  \n",
    "df.isnull() 의  반환값은 진위값으로 구성된 새로운 데이터프레임이다.  \n",
    "해당 데이터프레임의 해당 열의 합을 통해 누락 데이터의 개수를 구할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2 누락 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived :  0\n",
      "pclass :  0\n",
      "sex :  0\n",
      "age :  177\n",
      "sibsp :  0\n",
      "parch :  0\n",
      "fare :  0\n",
      "embarked :  2\n",
      "class :  0\n",
      "who :  0\n",
      "adult_male :  0\n",
      "deck :  688\n",
      "embark_town :  2\n",
      "alive :  0\n",
      "alone :  0\n"
     ]
    }
   ],
   "source": [
    "# isnull() 을 통해 각 원소가 NaN 인지에 대한 진위값 데이터프레임 생성\n",
    "missing_df = df.isnull()\n",
    "\n",
    "# for 반복문을 통한 각 열 NaN 개수 계산\n",
    "for col_name in missing_df.columns:\n",
    "    missing_count = missing_df[col_name].value_counts() # value_counts() 는 시리즈에 대해 고유한 값의 개수를 반환한다.\n",
    "    \n",
    "    try:        # missing_count 에 True 인덱스가 존재한다면, 그 개수를 출력\n",
    "        print(col_name, ': ', missing_count[True])  \n",
    "    except:     # missing_count 에 True 인덱스가 존재하지 않는다면, 0 을 출력\n",
    "        print(col_name, ': ', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
      "       'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터 포함 열 제거\n",
    "df_thresh = df.dropna(axis=1, thresh=500)\n",
    "print(df_thresh.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 머신러닝 분석을 할때도 deck 열과 같이 누락데이터가 많은 열은 제외하는 것이 좋다.  \n",
    "위의 코드에서는 df 의 dropna() 메소드를 각 열에 대해 수행하는데,  \n",
    "thresh 옵션을 통해 500 개 이상의 널값을 포함하는 열을 삭제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714 177 891\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터 포함 행 제거\n",
    "df_age = df.dropna(subset=['age'], how='any', axis=0)\n",
    "print(len(df_age), df['age'].isnull().sum(),len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age 열이 분석에 중요한 역할을 한다면, 해당 열에 널값이 있는 행을 제거하는것이 좋다.  \n",
    "dropna() 메소드를 사용하고 모든 행에 대해 (axis=0), age 열에 대해 (subset=['age])  \n",
    "Null 값이 하나라도 존재한다면 삭제한다 (how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3 누락 데이터 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 0\n"
     ]
    }
   ],
   "source": [
    "# 특정 열의 평균값 계산\n",
    "mean_age = df['age'].mean(axis=0)   # 산술연산이 가능한 값에 대해 평균값 계산\n",
    "\n",
    "# 특정 열의 NaN값 치환\n",
    "new_age_series = df['age'].fillna(mean_age)\n",
    "df['age'] = new_age_series\n",
    "print(df['age'].isnull().sum(), len(new_age_series) - new_age_series.isnull().value_counts()[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분석을 함에 있어 누락된 행/열을 전체 삭제하는 것 보다는 의미있는 데이터로 치환하는 것이  \n",
    "더욱 학습 결과를 좋게 만드는 경우가 많다.  \n",
    "  \n",
    "치환할 수 있는 데이터는 평균값, 최빈값 등의 분포/특성을 잘 나타낼 수 있는 데이터를 활용한다.  \n",
    "fillna() 메소드를 통해 해당 열의 NaN 값을 특정 값으로 채워 넣을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 특정 열의 최빈값 계산\n",
    "most_embark_town = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "\n",
    "# 특정 열의 NaN 값 치환\n",
    "df['embark_town'].fillna(most_embark_town, inplace=True)\n",
    "\n",
    "print(df['embark_town'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최빈값을 찾기 위해, df['embark_town'] 열에 대해 각 고유 원소의 개수를 세고,  \n",
    "그중 가장 큰 값을 가지는 원소를 idxmax() 메소드를 통해 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약, nan 과 같은 데이터로 누락 데이터가 표현 되지 않는 경우 (?, -, ...)  \n",
    "누락 데이터를 찾아 nan 으로 바꾸어주는 것이 좋다.  \n",
    "```ex) df.replace('?', np.nan, inplace=True)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 열의 nan 값을 이전 행의 값으로 치환\n",
    "df['embark_town'].fillna(method='ffill') # front fill\n",
    "\n",
    "# 특정 열의 nan 값을 다음 행의 값으로 치환\n",
    "df['embark_town'].fillna(method='bfill') # back fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 중복 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'c1': ['a','a','b','a','b'],\n",
    "    'c2': [1, 1, 1, 2, 2],\n",
    "    'c3': [1, 1, 2, 2, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# duplicated() 메소드\n",
    "df_dup = df.duplicated()\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(df_dup)\n",
    "print('\\n')\n",
    "print(type(df_dup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터프레임에서 하나의 행은 분석 대상이 갖고 있는 모든 속성(변수)에 대한 관측값(레코드)이다.  \n",
    "하나의 데이터셋에서 동일한 관측값이 2개 이상 중복되는 경우 (행이 중복되는 경우)  \n",
    "분석 결과를 왜곡하기 떄문에 중복 데이터를 찾아 삭제해야한다.  \n",
    "  \n",
    "df.duplicated() 메소드를 통해 전에 나온 행과 비교해 중복행일 경우 True 를 , 처음 행일 경우 False 를 가진 시리즈를 반환한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 특정 열에 대해 중복되는 행 찾기\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 중복 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'c1': ['a','a','b','a','b'],\n",
    "    'c2': [1, 1, 1, 2, 2],\n",
    "    'c3': [1, 1, 2, 2, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n"
     ]
    }
   ],
   "source": [
    "# drop_duplicates() 메소드\n",
    "delete_dup = df.drop_duplicates()\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(delete_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "3  a   2   2\n"
     ]
    }
   ],
   "source": [
    "# drop_duplicates() 메소드를 통해 특정 열의 중복 확인 후 제거\n",
    "delete_col_dup = df.drop_duplicates(subset=['c2'])\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(delete_col_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c2 열을 기준으로 중복을 판단할 경우, 0 행과 1,2 행이 중복되고  \n",
    "3 행과 4 행이 중복되므로 0 행과 3 행 이외에 모두 제거한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1 단위 환산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/part5/auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mpg</th>\n      <th>cylinders</th>\n      <th>displacement</th>\n      <th>horsepower</th>\n      <th>weight</th>\n      <th>acceleration</th>\n      <th>model year</th>\n      <th>origin</th>\n      <th>name</th>\n      <th>kpl</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>chevrolet chevelle malibu</td>\n      <td>7.65</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693.0</td>\n      <td>11.5</td>\n      <td>70</td>\n      <td>1</td>\n      <td>buick skylark 320</td>\n      <td>6.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436.0</td>\n      <td>11.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>plymouth satellite</td>\n      <td>7.65</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n      <td>amc rebel sst</td>\n      <td>6.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449.0</td>\n      <td>10.5</td>\n      <td>70</td>\n      <td>1</td>\n      <td>ford torino</td>\n      <td>7.23</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n0  18.0          8         307.0      130.0  3504.0          12.0          70   \n1  15.0          8         350.0      165.0  3693.0          11.5          70   \n2  18.0          8         318.0      150.0  3436.0          11.0          70   \n3  16.0          8         304.0      150.0  3433.0          12.0          70   \n4  17.0          8         302.0      140.0  3449.0          10.5          70   \n\n   origin                       name   kpl  \n0       1  chevrolet chevelle malibu  7.65  \n1       1          buick skylark 320  6.38  \n2       1         plymouth satellite  7.65  \n3       1              amc rebel sst  6.80  \n4       1                ford torino  7.23  "
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_to_kpl = 1.60934/3.78541\n",
    "\n",
    "df['kpl'] = df['mpg'] * mpg_to_kpl\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 데이터셋 내에서 다른 단위를 사용하거나, 필요한 단위가 아닐 경우  \n",
    "데이터의 일관성 측면에서 문제가 발생 할 수 있다.  \n",
    "따라서 해당 데이터 단위를 통일 시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 자료형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/part5/auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "mpg             float64\ncylinders         int64\ndisplacement    float64\nhorsepower       object\nweight          float64\nacceleration    float64\nmodel year        int64\norigin            int64\nname             object\ndtype: object"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 열의 데이터타입 확인\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. horsepower 는 int 가 적절하다.\n",
    "2. model year 와 origin 은 범주형이 적절하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n"
     ]
    }
   ],
   "source": [
    "# horsepower 열 고유값 출력\n",
    "print(df['horsepower'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변환과정에서 누락데이터 ? 에 의해 전체 열이 문자열로 인식되었음을 알 수 있따.  \n",
    "따라서 해당 결측값을 NaN 으로 변환하고 전체를 float 형으로 변환하는 것이 옳다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dtype('float64')"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 누락데이터('?')를 nan 으로 변경 후 nan 제거\n",
    "import numpy as np\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "df['horsepower'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 누락데이터 ? 를 numpy.nan 으로 변경\n",
    "2. 누락데이터 포함 행 제거\n",
    "3. 실수 변환 가능한 열의 값들을 실수로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before ['USA', 'JPN', 'EU']\n",
      "Categories (3, object): ['USA', 'JPN', 'EU']\n",
      "after ['USA', 'JPN', 'EU']\n",
      "Categories (3, object): ['USA', 'JPN', 'EU']\n",
      "category\n",
      "\n",
      "\n",
      "['USA', 'JPN', 'EU']\n",
      "Categories (3, object): ['USA', 'JPN', 'EU']\n",
      "category\n"
     ]
    }
   ],
   "source": [
    "# 정수형 데이터를 범주형 데이터로 변경\n",
    "print('before', df['origin'].unique())\n",
    "\n",
    "df['origin'].replace({\n",
    "    1: 'USA',\n",
    "    2: 'EU',\n",
    "    3: 'JPN'\n",
    "}, inplace=True)\n",
    "\n",
    "print('after', df['origin'].unique())\n",
    "print(df['origin'].dtypes)\n",
    "print('\\n')\n",
    "\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "origin 열의 값이 숫자에서 object 자료형으로 변경된 것을 알 수 있다.  \n",
    "이후 astype('category') 를 통해 해당 열의 전체 자료형을 category 자료형으로 변경 하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before category\n",
      "[70, 71, 72, 73, 74, ..., 78, 79, 80, 81, 82]\n",
      "Length: 13\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n",
      "\n",
      "\n",
      "after category\n",
      "[70, 71, 72, 73, 74, ..., 78, 79, 80, 81, 82]\n",
      "Length: 13\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "# model year 자료형 변경\n",
    "print('before' ,df['model year'].dtypes)\n",
    "print(df['model year'].unique())\n",
    "print('\\n')\n",
    "\n",
    "df['model year'] = df['model year'].astype('category')\n",
    "print('after' ,df['model year'].dtypes)\n",
    "print(df['model year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연도는 숫자로 해도 별 중요한 부분은 없지만, 데이터셋의 크기가 클 수록  \n",
    "연도 처럼 딱히 숫자 자체의 크기가 의미가 없는 데이터의 경우 범주형으로 표현해  \n",
    "고유의 기능은 유지하고 필요없는 부분을 제거하는 것이 옳다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 구간 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/part5/auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락 데이터 제거 및 자료형 변경\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터분석 알고리즘에서 연속 데이터를 그대로 사용하는것 보다는,  \n",
    "연속된 데이터를 의미있는 구간으로 쪼개고 해당 나눠진 구간을 분석하는 것이 의미가 더 큰 경우가 많다.  \n",
    "가격, 효율, 비용 등의 연속적인 데이터를 특정 구간으로 분할한 이산 데이터를 생성한다.  \n",
    "  \n",
    "연속 변수를 일정한 구간으로 나누고 각 구간을 범주형 이산 변수로 변환하는 과정을 ```구간 분할 (binning)``` 이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.         107.33333333 168.66666667 230.        ]\n"
     ]
    }
   ],
   "source": [
    "# np.historgram 메소드로 3개의 bin 으로 구분할 경계값의 리스트 계산\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(bin_dividers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 bins=3 을 통해 46~107 ... 총 3개의 구간 리스트를 생성했음을 알 수 있다.  \n",
    "3개의 구간을 위해 경계값이 총 4개가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horsepower horsepower_bin\n",
      "0       130.0           보통출력\n",
      "1       165.0           보통출력\n",
      "2       150.0           보통출력\n",
      "3       150.0           보통출력\n",
      "4       140.0           보통출력\n",
      "5       198.0            고출력\n",
      "6       220.0            고출력\n",
      "7       215.0            고출력\n",
      "8       225.0            고출력\n",
      "9       190.0            고출력\n"
     ]
    }
   ],
   "source": [
    "# 3개의 bin 에 이름 지정\n",
    "bin_names = ['저출력', '보통출력', '고출력']\n",
    "\n",
    "# pd.cut() 메소드를 통해 열의 데이터를 3개의 bin 에 할당\n",
    "df['horsepower_bin'] = pd.cut(\n",
    "                            x=df['horsepower'],\n",
    "                            bins=bin_dividers,\n",
    "                            labels=bin_names,\n",
    "                            include_lowest=True\n",
    "                            )\n",
    "\n",
    "print(df[['horsepower', 'horsepower_bin']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.cut 메소드의 인자는,  \n",
    "1. x = 분할 할 시리즈 데이터\n",
    "2. bins = 분할 할 경계값 리스트\n",
    "3. labels = 각 bin 의 이름\n",
    "4. 각 구간의 첫 경계값 포함 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 더미 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/part5/auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']\n",
    "\n",
    "# 누락 데이터 제거 및 자료형 변경\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "# np.histogram 을 통해 3개의 bin 에 대한 경계값 리스트 계산\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "\n",
    "# 3개 bin 이름 지정\n",
    "bin_names = ['저출력', '보통출력' ,'고출력']\n",
    "\n",
    "# pd.cut 을 통해 새로운 범주형 자료형 열 생성\n",
    "df['hp_bin'] = pd.cut(\n",
    "    x=df['horsepower'],\n",
    "    bins=bin_dividers,\n",
    "    labels=bin_names,\n",
    "    include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저출력  보통출력  고출력\n",
      "0     0     1    0\n",
      "1     0     1    0\n",
      "2     0     1    0\n",
      "3     0     1    0\n",
      "4     0     1    0\n",
      "5     0     0    1\n",
      "6     0     0    1\n",
      "7     0     0    1\n",
      "8     0     0    1\n",
      "9     0     0    1\n",
      "10    0     0    1\n",
      "11    0     1    0\n",
      "12    0     1    0\n",
      "13    0     0    1\n",
      "14    1     0    0\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# hp_bin 열의 범주형 데이터를 더미 변수로 변환\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "\n",
    "print(horsepower_dummies.head(15))\n",
    "print('\\n')\n",
    "print(type(horsepower_dummies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전의 코드에서 연속된 값을 가지는 데이터를 범주형 데이터로 변경하였다.  \n",
    "하지만, 실제 머신러닝 회귀분석등에서 사용할 때는 바로 사용 할 수 없는 경우가 잦고,  \n",
    "이를 위해 범주형 데이터를 컴퓨터가 인식가능한 입력값으로 변환해야 한다.  \n",
    "  \n",
    "이럴떄 숫자 0 또는 1 로 표현되는 ```더미변수 (dummy variable)``` 를 사용한다.  \n",
    "여기서 0 또는 1은 해당 특성이 존재하는지 없는지만을 의미한다.  \n",
    "  \n",
    "범주형 데이터를 컴퓨터가 인식 할 수 있도록 0, 1 로 구성되는 ```원핫벡터 (one hot vector)``` 로 바꾸는 것을  \n",
    "```원핫인코딩 (one-hot-encoding)``` 이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2] 15\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]]\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 0)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# sklearn 라이브러리를 통한 원핫인코딩\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 전처리를 위한 encoder 객체 생성\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "onehot_encoder = preprocessing.OneHotEncoder()\n",
    "\n",
    "# (1) label encoder 를 통해 문자열 범주를 숫자형 범주로 변환\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "print(onehot_labeled, len(onehot_labeled))\n",
    "print(type(onehot_labeled))\n",
    "print('\\n')\n",
    "\n",
    "# (2) 2차원 행렬로 변경\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled), 1)\n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))\n",
    "print('\\n')\n",
    "\n",
    "# (3) 희소행렬로 변환\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. preprocessing.LabelEncoder() 를 통해 문자열 범주를 숫자형 범주로 변환\n",
    "2. reshapre() 메소드를 통해 2차원 행렬로 변경\n",
    "3. preprocessing.OneHotEncoder() 를 통해 2차원 행렬을 희소행렬로 변경\n",
    "  \n",
    "1번 과정에 의해 저출력, 보통출력, 고출력은 각각 0,1,2 의 숫자형 범주로 변환되고  \n",
    "2번 과정에 의해 각 행에 대해 숫자형 범주를 적용한 값을 2차원 배열로 변환한다.  \n",
    "마지막으로 3번 과정에 의해 변환된 2차원 배열을 희소행렬로 변환한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/part5/auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']\n",
    "\n",
    "# 누락 데이터 제거 및 자료형 변경\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "count    392.000000\nmean     104.469388\nstd       38.491160\nmin       46.000000\n25%       75.000000\n50%       93.500000\n75%      126.000000\nmax      230.000000\nName: horsepower, dtype: float64"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# horsepower 열의 산술적 요약 정보 확인\n",
    "df['horsepower'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 변수(데이터프레임의 열)에 들어있는 숫자 데이터의 크기가 클 경우  \n",
    "머신러닝 분석의 결과치가 달라질 수 있다.  \n",
    "따라서 상대적인 숫자 데이터의 크기 차이를 제거하기 위해 각 열에 속하는 데이터 값을  \n",
    "동일한 크기 기준으로 나눈 비율로 나타내는것을 ```정규화 (normalization)``` 이라고 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.565217\n1    0.717391\n2    0.652174\n3    0.652174\n4    0.608696\n5    0.860870\n6    0.956522\n7    0.934783\n8    0.978261\n9    0.826087\nName: hp_div_max, dtype: float64"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 열의 최대값으로 나누기\n",
    "df['hp_div_max'] = df['horsepower'] / abs(df['horsepower'].max())\n",
    "df['hp_div_max'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.456522\n1    0.646739\n2    0.565217\n3    0.565217\n4    0.510870\n5    0.826087\n6    0.945652\n7    0.918478\n8    0.972826\n9    0.782609\nName: hp_max_min_nor, dtype: float64"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 열에서 최소값을 뺀  값을 분자로하고 최대값과 최소값의 차이를 분모로 하는 정규화\n",
    "x_minus_min = df['horsepower'] - df['horsepower'].min()\n",
    "max_minus_min = df['horsepower'].max() - df['horsepower'].min()\n",
    "df['hp_max_min_nor'] = x_minus_min / max_minus_min\n",
    "\n",
    "df['hp_max_min_nor'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1 다른 자료형을 시계열 객체로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date  Close  Start   High    Low  Volume\n",
      "0  2018-07-02  10100  10850  10900  10000  137977\n",
      "1  2018-06-29  10700  10550  10900   9990  170253\n",
      "2  2018-06-28  10400  10900  10950  10150  155769\n",
      "3  2018-06-27  10900  10800  11050  10500  133548\n",
      "4  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    20 non-null     object\n",
      " 1   Close   20 non-null     int64 \n",
      " 2   Start   20 non-null     int64 \n",
      " 3   High    20 non-null     int64 \n",
      " 4   Low     20 non-null     int64 \n",
      " 5   Volume  20 non-null     int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../../data/part5/stock-data.csv')\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 데이터는 시간 데이터임에도 불구하고 파이썬에서 사용하는 시계열 자료형 datetime 이 아닌 문자열, 숫자 등 다양한  \n",
    "자료형으로 존재 하는 경우가 많다.  \n",
    "이를 파이썬에 맞추어 ```pd.to_datetime()``` 메소드를 통해 datetime 자료형으로 변환한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      20 non-null     object        \n",
      " 1   Close     20 non-null     int64         \n",
      " 2   Start     20 non-null     int64         \n",
      " 3   High      20 non-null     int64         \n",
      " 4   Low       20 non-null     int64         \n",
      " 5   Volume    20 non-null     int64         \n",
      " 6   new_Date  20 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 1.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# pd.to_datetime() 메소드\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close  Start   High    Low  Volume\n",
      "new_Date                                      \n",
      "2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2018-07-02 to 2018-06-01\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Close   20 non-null     int64\n",
      " 1   Start   20 non-null     int64\n",
      " 2   High    20 non-null     int64\n",
      " 3   Low     20 non-null     int64\n",
      " 4   Volume  20 non-null     int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 960.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정\n",
    "df.set_index('new_Date', inplace=True)\n",
    "\n",
    "# 기존 Date 열은 삭제\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2 Timestamp 를 Period 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2021-01-02', '2021-02-01', '2021-02-12'], dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "\n",
      "PeriodIndex(['2021-01-02', '2021-02-01', '2021-02-12'], dtype='period[D]', freq='D')\n",
      "PeriodIndex(['2021-01', '2021-02', '2021-02'], dtype='period[M]', freq='M')\n",
      "PeriodIndex(['2021', '2021', '2021'], dtype='period[A-DEC]', freq='A-DEC')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dates = ['2021-01-02', '2021-02-01', '2021-02-12']\n",
    "\n",
    "# 문자열 날짜 배열을 timestamp 배열로 변환\n",
    "ts_dates = pd.to_datetime(dates)\n",
    "print(ts_dates)\n",
    "print('\\n')\n",
    "\n",
    "# timestamp 를 period 로 변환\n",
    "pr_day = ts_dates.to_period(freq='D')\n",
    "print(pr_day)\n",
    "pr_mon = ts_dates.to_period(freq='M')\n",
    "print(pr_mon)\n",
    "pr_year = ts_dates.to_period(freq='Y')\n",
    "print(pr_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3 시계열 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-01 00:00:00+09:00', '2020-02-01 00:00:00+09:00',\n",
      "               '2020-03-01 00:00:00+09:00', '2020-04-01 00:00:00+09:00',\n",
      "               '2020-05-01 00:00:00+09:00', '2020-06-01 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Timestamp 배열 생성 - 월 간격, 월의 시작일 기준\n",
    "ts_ms = pd.date_range(\n",
    "    start='2020-01-01',\n",
    "    end=None,\n",
    "    periods=6,\n",
    "    freq='MS',\n",
    "    tz='Asia/Seoul'\n",
    ")\n",
    "\n",
    "print(ts_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2020-01-31 00:00:00+09:00', '2020-02-29 00:00:00+09:00',\n",
      "               '2020-03-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00',\n",
      "               '2020-05-31 00:00:00+09:00', '2020-06-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='M')\n",
      "\n",
      "\n",
      "DatetimeIndex(['2020-01-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00',\n",
      "               '2020-07-31 00:00:00+09:00', '2020-10-31 00:00:00+09:00',\n",
      "               '2021-01-31 00:00:00+09:00', '2021-04-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='3M')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Timestamp 배열 생성 - 월 간격, 월의 마지막일 기준\n",
    "ts_me = pd.date_range(\n",
    "    start='2020-01-01',\n",
    "    end=None,\n",
    "    periods=6,\n",
    "    freq='M',\n",
    "    tz='Asia/Seoul'\n",
    ")\n",
    "\n",
    "print(ts_me)\n",
    "print('\\n')\n",
    "\n",
    "# Timestamp 배열 생성 - 3개월(1분기) 간격, 월의 마지막일 기준\n",
    "ts_3m = pd.date_range(\n",
    "    start='2020-01-01',\n",
    "    end=None,\n",
    "    periods=6,\n",
    "    freq='3M',\n",
    "    tz='Asia/Seoul'\n",
    ")\n",
    "\n",
    "print(ts_3m)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-4 시계열 데이터 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Close</th>\n      <th>Start</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Volume</th>\n      <th>new_Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-07-02</td>\n      <td>10100</td>\n      <td>10850</td>\n      <td>10900</td>\n      <td>10000</td>\n      <td>137977</td>\n      <td>2018-07-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-06-29</td>\n      <td>10700</td>\n      <td>10550</td>\n      <td>10900</td>\n      <td>9990</td>\n      <td>170253</td>\n      <td>2018-06-29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-06-28</td>\n      <td>10400</td>\n      <td>10900</td>\n      <td>10950</td>\n      <td>10150</td>\n      <td>155769</td>\n      <td>2018-06-28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-06-27</td>\n      <td>10900</td>\n      <td>10800</td>\n      <td>11050</td>\n      <td>10500</td>\n      <td>133548</td>\n      <td>2018-06-27</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-06-26</td>\n      <td>10800</td>\n      <td>10900</td>\n      <td>11000</td>\n      <td>10700</td>\n      <td>63039</td>\n      <td>2018-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date  Close  Start   High    Low  Volume   new_Date\n0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../data/part5/stock-data.csv')\n",
    "\n",
    "# 문자열인 날짜 데이터를 Timestamp 자료형으로 변경\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Close</th>\n      <th>Start</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Volume</th>\n      <th>new_Date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-07-02</td>\n      <td>10100</td>\n      <td>10850</td>\n      <td>10900</td>\n      <td>10000</td>\n      <td>137977</td>\n      <td>2018-07-02</td>\n      <td>2018</td>\n      <td>7</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-06-29</td>\n      <td>10700</td>\n      <td>10550</td>\n      <td>10900</td>\n      <td>9990</td>\n      <td>170253</td>\n      <td>2018-06-29</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-06-28</td>\n      <td>10400</td>\n      <td>10900</td>\n      <td>10950</td>\n      <td>10150</td>\n      <td>155769</td>\n      <td>2018-06-28</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-06-27</td>\n      <td>10900</td>\n      <td>10800</td>\n      <td>11050</td>\n      <td>10500</td>\n      <td>133548</td>\n      <td>2018-06-27</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-06-26</td>\n      <td>10800</td>\n      <td>10900</td>\n      <td>11000</td>\n      <td>10700</td>\n      <td>63039</td>\n      <td>2018-06-26</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date  Close  Start   High    Low  Volume   new_Date  year  month  day\n0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7    2\n1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   29\n2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   28\n3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   27\n4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   26"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dt 속성을 이용하여 timestamp 의 연/월/일 정보를 년/월/일 컬럼에 삽입\n",
    "df['year'] = df['new_Date'].dt.year\n",
    "df['month'] = df['new_Date'].dt.month\n",
    "df['day'] = df['new_Date'].dt.day\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Close</th>\n      <th>Start</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Volume</th>\n      <th>new_Date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>p_year</th>\n      <th>p_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-07-02</td>\n      <td>10100</td>\n      <td>10850</td>\n      <td>10900</td>\n      <td>10000</td>\n      <td>137977</td>\n      <td>2018-07-02</td>\n      <td>2018</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2018</td>\n      <td>2018-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-06-29</td>\n      <td>10700</td>\n      <td>10550</td>\n      <td>10900</td>\n      <td>9990</td>\n      <td>170253</td>\n      <td>2018-06-29</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>29</td>\n      <td>2018</td>\n      <td>2018-06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-06-28</td>\n      <td>10400</td>\n      <td>10900</td>\n      <td>10950</td>\n      <td>10150</td>\n      <td>155769</td>\n      <td>2018-06-28</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>28</td>\n      <td>2018</td>\n      <td>2018-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-06-27</td>\n      <td>10900</td>\n      <td>10800</td>\n      <td>11050</td>\n      <td>10500</td>\n      <td>133548</td>\n      <td>2018-06-27</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>27</td>\n      <td>2018</td>\n      <td>2018-06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-06-26</td>\n      <td>10800</td>\n      <td>10900</td>\n      <td>11000</td>\n      <td>10700</td>\n      <td>63039</td>\n      <td>2018-06-26</td>\n      <td>2018</td>\n      <td>6</td>\n      <td>26</td>\n      <td>2018</td>\n      <td>2018-06</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date  Close  Start   High    Low  Volume   new_Date  year  month  \\\n0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7   \n1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   \n2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   \n3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   \n4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   \n\n   day p_year  p_month  \n0    2   2018  2018-07  \n1   29   2018  2018-06  \n2   28   2018  2018-06  \n3   27   2018  2018-06  \n4   26   2018  2018-06  "
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dt 를 통해 추출한 값을 pd.to_period() 메소드를 사용해 period 로 변환\n",
    "df['p_year'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['p_month'] = df['new_Date'].dt.to_period(freq='M')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "DatetimeIndex(['2018-07-02', '2018-06-29', '2018-06-28', '2018-06-27',\n",
      "               '2018-06-26', '2018-06-25', '2018-06-22', '2018-06-21',\n",
      "               '2018-06-20', '2018-06-19', '2018-06-18', '2018-06-15',\n",
      "               '2018-06-14', '2018-06-12', '2018-06-11', '2018-06-08',\n",
      "               '2018-06-07', '2018-06-05', '2018-06-04', '2018-06-01'],\n",
      "              dtype='datetime64[ns]', name='new_Date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스 활용하기\n",
    "df.set_index('new_Date', inplace=True)\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp 로 구성된 열을 행 인덱스로 지정할 경우 DatetimeIndex 라는 고유 속성으로 변환된다.  \n",
    "마찬가지로 Period 로 구성된 열을 행 인덱스로 지정할 경우 PeriodIndex 라는 고유 속성으로 변환된다.  \n",
    "이와 같이 날짜 인덱스를 활용하면 시계열 데이터에 대한 인덱싱과 슬라이싱이 매우 편해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-06-01  2018-06-01  11900  11800  12100  11750   32062\n",
      "2018-06-04  2018-06-04  11900  11900  12200  11700   25171\n",
      "2018-06-05  2018-06-05  12150  11800  12250  11800   42485\n",
      "2018-06-07  2018-06-07  11950  12200  12300  11900   49088\n",
      "2018-06-08  2018-06-08  11950  11950  12200  11800   59258\n",
      "2018-06-11  2018-06-11  11950  12000  12250  11950   62293\n",
      "2018-06-12  2018-06-12  13200  12200  13300  12050  558148\n",
      "2018-06-14  2018-06-14  13450  13200  13700  13150  347451\n",
      "2018-06-15  2018-06-15  13400  13600  13600  12900  201376\n",
      "2018-06-18  2018-06-18  12000  13400  13400  12000  309787\n",
      "2018-06-19  2018-06-19  11300  11850  11950  11300  180656\n",
      "2018-06-20  2018-06-20  11550  11200  11600  10900  308596\n",
      "2018-06-21  2018-06-21  11200  11350  11750  11200  133002\n",
      "2018-06-22  2018-06-22  11300  11250  11450  10750  134805\n",
      "2018-06-25  2018-06-25  11150  11400  11450  11000   55519\n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039\n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "\n",
      "\n",
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스를 통해 데이터 선택하기\n",
    "df = df.sort_index() # AssertionError: <class 'numpy.ndarray'> 에러 발생시 정렬후 수행 할 것.\n",
    "\n",
    "df_y = df['2018']\n",
    "print(df_y)\n",
    "print('\\n')\n",
    "\n",
    "df_m = df['2018-07']\n",
    "print(df_m)\n",
    "print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}